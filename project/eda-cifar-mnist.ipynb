{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def get_transforms(std=0.5, mean=0.5):\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((mean,), (std,))\n",
    "    ])\n",
    "    \n",
    "def cut_data(data, first_proportion=0.8):\n",
    "    first_size = int(len(data) * first_proportion)\n",
    "    second_size = len(data) - first_size\n",
    "    first_data, second_data = torch.utils.data.random_split(data, [first_size, second_size])\n",
    "    return first_data, second_data\n",
    "\n",
    "def get_data_MNIST(std=0.5, mean=0.5, train_size=0.8):\n",
    "    train_data = datasets.MNIST(root='data', train=True, transform=get_transforms(std, mean), download=True)\n",
    "    test_data = datasets.MNIST(root='data', train=False, transform=get_transforms(std, mean), download=True)\n",
    "    train_data, val_data = cut_data(train_data, train_size)\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def get_data_CIFAR10(std=0.5, mean=0.5, train_size=0.8):\n",
    "    train_data = datasets.CIFAR10(root='data', train=True, transform=get_transforms(std, mean), download=True)\n",
    "    test_data = datasets.CIFAR10(root='data', train=False, transform=get_transforms(std, mean), download=True)\n",
    "    train_data, val_data = cut_data(train_data, train_size)\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def inspect(data):\n",
    "    print(f\"Data type: {type(data)}\")\n",
    "    print(f\"Data length: {len(data)}\")\n",
    "    print(f\"Data shape: {data[0][0].shape}\")\n",
    "    \n",
    "def check_data(train_data, val_data, test_data):\n",
    "    inspect(train_data)\n",
    "    inspect(val_data)\n",
    "    inspect(test_data)\n",
    "    # Total de datos\n",
    "    print(f\"Total data: {len(train_data) + len(val_data) + len(test_data)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: <class 'torch.utils.data.dataset.Subset'>\n",
      "Data length: 48000\n",
      "Data shape: torch.Size([1, 28, 28])\n",
      "Data type: <class 'torch.utils.data.dataset.Subset'>\n",
      "Data length: 12000\n",
      "Data shape: torch.Size([1, 28, 28])\n",
      "Data type: <class 'torchvision.datasets.mnist.MNIST'>\n",
      "Data length: 10000\n",
      "Data shape: torch.Size([1, 28, 28])\n",
      "Total data: 70000\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Data type: <class 'torch.utils.data.dataset.Subset'>\n",
      "Data length: 40000\n",
      "Data shape: torch.Size([3, 32, 32])\n",
      "Data type: <class 'torch.utils.data.dataset.Subset'>\n",
      "Data length: 10000\n",
      "Data shape: torch.Size([3, 32, 32])\n",
      "Data type: <class 'torchvision.datasets.cifar.CIFAR10'>\n",
      "Data length: 10000\n",
      "Data shape: torch.Size([3, 32, 32])\n",
      "Total data: 60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_mnist, val_mnist, test_mnist = get_data_MNIST()\n",
    "check_data(train_mnist, val_mnist, test_mnist)\n",
    "train_cifar10, val_cifar10, test_cifar10 = get_data_CIFAR10()\n",
    "check_data(train_cifar10, val_cifar10, test_cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotear una imagen de ejemplo\n",
    "def plot_image(data, index):\n",
    "    image, label = data[index]\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    # Check rgb or grayscale\n",
    "    if image.shape[0] == 1:\n",
    "        image = image[0]\n",
    "        plt.imshow(image, cmap='gray')\n",
    "    else:\n",
    "        image = image.permute(1, 2, 0)\n",
    "        plt.imshow(image)\n",
    "    plt.title(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(train_mnist, 10)\n",
    "plot_image(train_cifar10, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una capa de convolución\n",
    "\n",
    "class ConvLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=1):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))\n",
    "    \n",
    "# Max Pooling + Batch Normalization + Dropout (opcional)\n",
    "class MaxPoolBN(torch.nn.Module): \n",
    "    def __init__(self, in_channels, kernel_size = 2, stride=2, padding=0, dropout=0.1):\n",
    "        super(MaxPoolBN, self).__init__()\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        self.bn = torch.nn.BatchNorm2d(in_channels)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.bn(self.max_pool(x)))\n",
    "    \n",
    "# Capa densa + dropout (opcional)\n",
    "class Dense(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.1):\n",
    "        super(Dense, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features, out_features)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.linear(x))\n",
    "    \n",
    "# structure = [L1, k1, ..., Ln, kn], con L la cantidad de capas y k el kernel size\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self,in_channels, structure, size=28, classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.size = size\n",
    "        self.structure = structure\n",
    "        self.L = [structure[i] for i in range(len(structure)) if i % 2 == 0]\n",
    "        self.k = [structure[i] for i in range(len(structure)) if i % 2 == 1]\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(len(self.L)):\n",
    "            if i == 0:\n",
    "                self.layers.append(ConvLayer(in_channels, self.L[i], self.k[i]))\n",
    "            else:\n",
    "                self.layers.append(ConvLayer(self.L[i-1], self.L[i], self.k[i]))\n",
    "            \n",
    "            # Max pooling en cantidad par de capas \n",
    "            if i % 2 == 1:\n",
    "                self.layers.append(MaxPoolBN(self.L[i], 2))\n",
    "                self.size = self.size // 2\n",
    "                \n",
    "        # Caso impares\n",
    "        if len(self.L) % 2 == 1:\n",
    "            self.layers.append(MaxPoolBN(self.L[-1], 2))\n",
    "            self.size = self.size // 2\n",
    "            \n",
    "        # Cabeza clasificadora\n",
    "        self.layers.append(torch.nn.Flatten())\n",
    "        self.layers.append(Dense(self.L[-1] * self.size * self.size, 128))\n",
    "        self.layers.append(Dense(128, classes))\n",
    "                \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "# Profundidad de CIFAR10 (32/2^4 = 2 -> 4x2 capas convolucionales maximo) depth in [2,8]\n",
    "# E:32 --c1--> 32 --c2--> 32 --MP-->\n",
    "# 16 --c3--> 16 --c4--> 16 --MP-->\n",
    "# 8 --c5--> 8 --c6--> 8 --MP-->\n",
    "# 4 --c7--> 4 --c8--> 4 --MP--> 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Probar con un batch de entrada 1 x 1 x 28 x 28\n",
    "# Cargamos el dataset de CIFAR10\n",
    "train_data, val_data, test_data = get_data_CIFAR10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 32, 32])\n",
      "ConvNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): ConvLayer(\n",
      "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): ConvLayer(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): MaxPoolBN(\n",
      "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): ConvLayer(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): ConvLayer(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): MaxPoolBN(\n",
      "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (6-7): 2 x ConvLayer(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (8): MaxPoolBN(\n",
      "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (9): ConvLayer(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (10): ConvLayer(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (11): MaxPoolBN(\n",
      "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (12): Flatten(start_dim=1, end_dim=-1)\n",
      "    (13): Dense(\n",
      "      (linear): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (14): Dense(\n",
      "      (linear): Linear(in_features=128, out_features=10, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Creamos el modelo\n",
    "L = [64, 64, 128, 128, 128, 128, 64, 64]\n",
    "k = [ 3,  3,   3,   3,   3,   3,  3,  3]\n",
    "structure = [item for sublist in [[L[i], k[i]] for i in range(len(L)) ] for item in sublist]\n",
    "\n",
    "# Obtener un ejemplo de entrada\n",
    "x, y = train_data[0]\n",
    "x = x.unsqueeze(0)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "# Creamos el modelo\n",
    "model = ConvNet(3, structure, size=32, classes=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos el modelo\n",
    "y_pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar un modelo\n",
    "def train(model, train_data, val_data, epochs=100, batch_size=256, lr=0.001, device='cpu', folder='models'):\n",
    "    # Definimos el optimizador\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # Definimos la función de costo\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # Enviamos el modelo al dispositivo\n",
    "    model.to(device)\n",
    "    # Definimos los dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    # Definimos las listas para guardar los resultados\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    # Early stopping\n",
    "    epochs_without_improvement = 0\n",
    "    # Entrenamos\n",
    "    for epoch in range(epochs):\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for x, y in train_loader:\n",
    "            # Enviamos los datos al dispositivo\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # Forward\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Acumulamos los resultados\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (y_pred.argmax(1) == y).sum().item()\n",
    "        # Promediamos los resultados\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc /= len(train_loader.dataset)\n",
    "        # Evaluación\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        for x, y in val_loader:\n",
    "            # Enviamos los datos al dispositivo\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # Forward\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "            # Acumulamos los resultados\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (y_pred.argmax(1) == y).sum().item()\n",
    "        # Promediamos los resultados\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc /= len(val_loader.dataset)\n",
    "        # Guardamos los resultados\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        # Si mejora el resultado, guardamos el modelo\n",
    "        best_val_loss = np.min(val_losses)\n",
    "        if val_loss > best_val_loss:\n",
    "            torch.save(model.state_dict(), f\"{folder}/model.pth\")\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        # Si no mejora el resultado durante 10 epochs, detenemos el entrenamiento\n",
    "        if epochs_without_improvement == 10:\n",
    "            print(f\"Training stopped at epoch {epoch+1}\")\n",
    "            break\n",
    "        # Imprimimos los resultados\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"Train loss: {train_loss:.4f} - Train acc: {train_acc:.4f}\")\n",
    "        print(f\"Val loss: {val_loss:.4f} - Val acc: {val_acc:.4f}\")\n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:\n",
      "Train loss: 0.0057 - Train acc: 0.4723\n",
      "Val loss: 0.0043 - Val acc: 0.6126\n",
      "Epoch 2/100:\n",
      "Train loss: 0.0040 - Train acc: 0.6396\n",
      "Val loss: 0.0036 - Val acc: 0.6730\n",
      "Epoch 3/100:\n",
      "Train loss: 0.0031 - Train acc: 0.7182\n",
      "Val loss: 0.0033 - Val acc: 0.7145\n",
      "Epoch 4/100:\n",
      "Train loss: 0.0027 - Train acc: 0.7585\n",
      "Val loss: 0.0025 - Val acc: 0.7854\n",
      "Epoch 5/100:\n",
      "Train loss: 0.0023 - Train acc: 0.7898\n",
      "Val loss: 0.0025 - Val acc: 0.7868\n",
      "Epoch 6/100:\n",
      "Train loss: 0.0020 - Train acc: 0.8176\n",
      "Val loss: 0.0028 - Val acc: 0.7714\n",
      "Epoch 7/100:\n",
      "Train loss: 0.0018 - Train acc: 0.8361\n",
      "Val loss: 0.0023 - Val acc: 0.8098\n",
      "Epoch 8/100:\n",
      "Train loss: 0.0016 - Train acc: 0.8532\n",
      "Val loss: 0.0025 - Val acc: 0.8023\n",
      "Epoch 9/100:\n",
      "Train loss: 0.0014 - Train acc: 0.8660\n",
      "Val loss: 0.0024 - Val acc: 0.8199\n",
      "Epoch 10/100:\n",
      "Train loss: 0.0013 - Train acc: 0.8782\n",
      "Val loss: 0.0023 - Val acc: 0.8320\n",
      "Epoch 11/100:\n",
      "Train loss: 0.0011 - Train acc: 0.8912\n",
      "Val loss: 0.0024 - Val acc: 0.8296\n",
      "Epoch 12/100:\n",
      "Train loss: 0.0010 - Train acc: 0.8972\n",
      "Val loss: 0.0024 - Val acc: 0.8358\n",
      "Epoch 13/100:\n",
      "Train loss: 0.0010 - Train acc: 0.9024\n",
      "Val loss: 0.0023 - Val acc: 0.8391\n",
      "Epoch 14/100:\n",
      "Train loss: 0.0008 - Train acc: 0.9174\n",
      "Val loss: 0.0026 - Val acc: 0.8342\n",
      "Epoch 15/100:\n",
      "Train loss: 0.0009 - Train acc: 0.9122\n",
      "Val loss: 0.0028 - Val acc: 0.8285\n",
      "Epoch 16/100:\n",
      "Train loss: 0.0008 - Train acc: 0.9190\n",
      "Val loss: 0.0028 - Val acc: 0.8356\n",
      "Epoch 17/100:\n",
      "Train loss: 0.0007 - Train acc: 0.9259\n",
      "Val loss: 0.0029 - Val acc: 0.8358\n",
      "Epoch 18/100:\n",
      "Train loss: 0.0007 - Train acc: 0.9244\n",
      "Val loss: 0.0027 - Val acc: 0.8386\n",
      "Epoch 19/100:\n",
      "Train loss: 0.0007 - Train acc: 0.9296\n",
      "Val loss: 0.0028 - Val acc: 0.8405\n",
      "Epoch 20/100:\n",
      "Train loss: 0.0006 - Train acc: 0.9315\n",
      "Val loss: 0.0030 - Val acc: 0.8382\n",
      "Epoch 21/100:\n",
      "Train loss: 0.0006 - Train acc: 0.9329\n",
      "Val loss: 0.0030 - Val acc: 0.8443\n",
      "Epoch 22/100:\n",
      "Train loss: 0.0006 - Train acc: 0.9346\n",
      "Val loss: 0.0028 - Val acc: 0.8476\n",
      "Epoch 23/100:\n",
      "Train loss: 0.0005 - Train acc: 0.9394\n",
      "Val loss: 0.0031 - Val acc: 0.8446\n",
      "Epoch 24/100:\n",
      "Train loss: 0.0006 - Train acc: 0.9368\n",
      "Val loss: 0.0030 - Val acc: 0.8470\n",
      "Epoch 25/100:\n",
      "Train loss: 0.0005 - Train acc: 0.9391\n",
      "Val loss: 0.0029 - Val acc: 0.8527\n",
      "Epoch 26/100:\n",
      "Train loss: 0.0005 - Train acc: 0.9414\n",
      "Val loss: 0.0031 - Val acc: 0.8489\n",
      "Epoch 27/100:\n",
      "Train loss: 0.0005 - Train acc: 0.9400\n",
      "Val loss: 0.0031 - Val acc: 0.8453\n",
      "Epoch 28/100:\n",
      "Train loss: 0.0005 - Train acc: 0.9406\n",
      "Val loss: 0.0030 - Val acc: 0.8495\n",
      "Epoch 29/100:\n",
      "Train loss: 0.0005 - Train acc: 0.9436\n",
      "Val loss: 0.0030 - Val acc: 0.8538\n",
      "Epoch 30/100:\n",
      "Train loss: 0.0005 - Train acc: 0.9466\n",
      "Val loss: 0.0034 - Val acc: 0.8445\n",
      "Epoch 31/100:\n",
      "Train loss: 0.0005 - Train acc: 0.9426\n",
      "Val loss: 0.0032 - Val acc: 0.8443\n",
      "Epoch 32/100:\n",
      "Train loss: 0.0005 - Train acc: 0.9491\n",
      "Val loss: 0.0033 - Val acc: 0.8468\n",
      "Epoch 33/100:\n",
      "Train loss: 0.0005 - Train acc: 0.9449\n",
      "Val loss: 0.0032 - Val acc: 0.8490\n",
      "Epoch 34/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9485\n",
      "Val loss: 0.0033 - Val acc: 0.8537\n",
      "Epoch 35/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9489\n",
      "Val loss: 0.0032 - Val acc: 0.8456\n",
      "Epoch 36/100:\n",
      "Train loss: 0.0005 - Train acc: 0.9452\n",
      "Val loss: 0.0031 - Val acc: 0.8534\n",
      "Epoch 37/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9489\n",
      "Val loss: 0.0032 - Val acc: 0.8500\n",
      "Epoch 38/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9467\n",
      "Val loss: 0.0034 - Val acc: 0.8469\n",
      "Epoch 39/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9487\n",
      "Val loss: 0.0034 - Val acc: 0.8477\n",
      "Epoch 40/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9480\n",
      "Val loss: 0.0032 - Val acc: 0.8495\n",
      "Epoch 41/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9492\n",
      "Val loss: 0.0035 - Val acc: 0.8481\n",
      "Epoch 42/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9519\n",
      "Val loss: 0.0034 - Val acc: 0.8503\n",
      "Epoch 43/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9496\n",
      "Val loss: 0.0033 - Val acc: 0.8504\n",
      "Epoch 44/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9493\n",
      "Val loss: 0.0032 - Val acc: 0.8544\n",
      "Epoch 45/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9523\n",
      "Val loss: 0.0035 - Val acc: 0.8524\n",
      "Epoch 46/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9508\n",
      "Val loss: 0.0036 - Val acc: 0.8488\n",
      "Epoch 47/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9488\n",
      "Val loss: 0.0034 - Val acc: 0.8499\n",
      "Epoch 48/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9525\n",
      "Val loss: 0.0034 - Val acc: 0.8510\n",
      "Epoch 49/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9520\n",
      "Val loss: 0.0037 - Val acc: 0.8403\n",
      "Epoch 50/100:\n",
      "Train loss: 0.0004 - Train acc: 0.9491\n",
      "Val loss: 0.0036 - Val acc: 0.8475\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Entrenamos el modelo\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_losses, train_accuracies, val_losses, val_accuracies \u001b[39m=\u001b[39m train(model, train_data, val_data, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[18], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_data, val_data, epochs, batch_size, lr, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     22\u001b[0m train_acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     24\u001b[0m     \u001b[39m# Enviamos los datos al dispositivo\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     26\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\Drive-Seba\\UChile\\9no semestre\\Procesamiento de Imagenes\\Genetic-Algorithms\\.env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Drive-Seba\\UChile\\9no semestre\\Procesamiento de Imagenes\\Genetic-Algorithms\\.env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Drive-Seba\\UChile\\9no semestre\\Procesamiento de Imagenes\\Genetic-Algorithms\\.env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Drive-Seba\\UChile\\9no semestre\\Procesamiento de Imagenes\\Genetic-Algorithms\\.env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Drive-Seba\\UChile\\9no semestre\\Procesamiento de Imagenes\\Genetic-Algorithms\\.env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[1;32md:\\Drive-Seba\\UChile\\9no semestre\\Procesamiento de Imagenes\\Genetic-Algorithms\\.env\\lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    115\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32md:\\Drive-Seba\\UChile\\9no semestre\\Procesamiento de Imagenes\\Genetic-Algorithms\\.env\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32md:\\Drive-Seba\\UChile\\9no semestre\\Procesamiento de Imagenes\\Genetic-Algorithms\\.env\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32md:\\Drive-Seba\\UChile\\9no semestre\\Procesamiento de Imagenes\\Genetic-Algorithms\\.env\\lib\\site-packages\\torchvision\\transforms\\functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    170\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mview(pic\u001b[39m.\u001b[39msize[\u001b[39m1\u001b[39m], pic\u001b[39m.\u001b[39msize[\u001b[39m0\u001b[39m], F_pil\u001b[39m.\u001b[39mget_image_num_channels(pic))\n\u001b[0;32m    171\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mpermute((\u001b[39m2\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[0;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train(model, train_data, val_data, epochs=100, batch_size=256, lr=0.001, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
